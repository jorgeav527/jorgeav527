+++
title = "AWS Certified Cloud Practitioner Certification"
date = "2025-03-05T14:46:35-05:00"
#dateFormat = "2006-01-02" # This value can be configured for per-post date formatting
author = ""
authorTwitter = "" #do not include @
cover = ""
tags = ["AWS", "DevOps"]
description = "How to become a Cloud Practitioner?"
+++

## 1. Cloud computing

### What is a client-server model?

In computing, a **client** can be a web browser or desktop application that a person interacts with to make requests to computer servers. A **server** can be services, such as a remote system (hardware or software) that processes requests and returns responses like (AWS EC2, Google Cloud).

{{< image src="https://i.imgur.com/EU6eyA6.png" alt="Hello Friend" position="center" >}}

### What are the deployment models?

{{< details summary="Cloud-Based">}}
Run, migrate, or build applications in the cloud.
- Use case: *An application built with virtual servers, databases, and networking components, fully based in the cloud.*
{{< /details >}}
{{< details summary="On-Premises">}}
Resources are deployed in on-premises data centers.
- Use case: *Applications running on technology fully kept in an on-premises data center with enhanced resource utilization.*
{{< /details >}}
{{< details summary="Hybrid">}}
Combines cloud-based and on-premises resources.
- Use case: *Legacy applications remain on premises, while batch data processing and analytics services run in the cloud.* or *Suitable for legacy applications with regulatory requirements for cloud integration.*
{{< /details >}}

### What are the benefits of cloud computing?

{{< details summary="Trade Upfront Expense for Variable Expense">}}
- Upfront Expense: Traditional IT requires heavy initial investment in data centers, servers, and infrastructure before usage.
- Variable Expense: Cloud computing allows businesses to pay only for the resources they consume, avoiding large capital expenditures.
{{< /details >}}

{{< details summary="Stop Spending Money on Data Center Maintenance">}}
- Traditional Challenge: Computing in data centers often requires you to spend more money and time managing infrastructure and servers.
- Cloud Advantage: Cloud computing eliminates the burden of maintaining physical hardware, allowing businesses to focus on applications and customers.
- Key Benefit: Is the ability to focus less on these tasks and more on your applications and customers.
{{< /details >}}

{{< details summary="Stop Guessing Capacity">}}
- Traditional Challenge: You don’t have to predict how much infrastructure capacity you will need before deploying an application.
- Cloud Advantage: Cloud providers offer auto-scaling features that adjust resources based on demand.
{{< /details >}}

{{< details summary="Benefit from massive economies of scale">}}
By using cloud computing, you can achieve a lower variable cost than you can get on your own.
{{< /details >}}

{{< details summary="Increase speed and agility">}}
The flexibility of cloud computing makes it easier for you to develop and deploy applications.
{{< /details >}}

{{< details summary="Go global in minutes">}}
The global footprint of the AWS Cloud enables you to deploy applications to customers around the world quickly, while providing them with low latency. This means that even if you are located in a different part of the world than your customers, customers are able to access your applications with minimal delays.
{{< /details >}}

## 2. EC2

- Amazon Elastic Compute Cloud (EC2) provides secure and resizable compute capacity in the cloud.
- EC2 instances are isolated from each other, ensuring secure multitenant environments.
- **Multitenancy**: Instances share physical hardware securely using a hypervisor.
- **Configuration Control**: Customize the operating system (Windows or Linux), software, and networking settings.
- **Resizable Instances**: Adjust instance size based on resource needs.
- **Networking Control**: Define public or private access to instances.

### What types of EC2 instances exist?

{{< details summary="General purpose instances">}}
Provide a balance of compute, memory, and networking resources.
Applications built on open source software such as
- Backend servers for enterprise applications
- Microservices
- Caching fleets
- Gaming servers
- Small and medium databases
{{< /details >}}

{{< details summary="Compute optimized instances">}}
Compute-bound applications that benefit from high-performance processors.
- Compute-intensive applications servers
- Dedicated gaming servers
- High performance web servers
- High performance computing (HPC)
- Media transcoding
- Scientific modeling
- Dedicated gaming servers
- Machine learning inference
- Batch processing workloads that require processing many transactions in a single group
- Video encoding
- Scientific modeling
- Distributed analytics
{{< /details >}}

{{< details summary="Memory optimized instances">}}
Designed to deliver fast performance for workloads that process large datasets in memory.
- High-performance database, in-memory caches
- Real-time processing of a large amount of unstructured data
- Real-time big data analytics.
{{< /details >}}

{{< details summary="Accelerated computing instances">}}
Use hardware accelerators, or coprocessors, to perform some functions more efficiently than is possible in software running on CPUs.
- Generative AI applications, including question answering, code generation, video and image generation, speech recognition, and more.
- HPC applications at scale in pharmaceutical discovery, seismic analysis, weather forecasting, and financial modeling.
- Functions include floating-point number calculations
- Graphics applications processing
- Data pattern matching
- Game streaming
{{< /details >}}

{{< details summary="Storage optimized instances">}}
Are designed for workloads that require high, sequential read and write access to very large data sets on local storage
Storage optimized instances are designed to deliver tens of thousands of low-latency, random IOPS.
- I/O intensive workloads that require real-time latency access to data such as relational databases (MySQL, PostgreSQL)
- Real-time databases, NoSQL databases (Aerospike, Apache Druid, Clickhouse, MongoDB)
- Real- time analytics such as Apache Spark.
- Distributed file systems
- Data warehousing applications
- High-frequency online transaction processing (OLTP) systems
{{< /details >}}

### What types of EC2 pricing exist?

{{< details summary="On-Demand Instances">}}
Ideal for short-term, irregular workloads that cannot be interrupted.
{{< /details >}}

{{< details summary="Reserved Instances">}}
You can purchase Standard Reserved and Convertible Reserved Instances for a 1-year or 3-year term. You realize greater cost savings with the 3-year option. Types include:
- Standard Reserved Instances: Best when you know the exact EC2 instance type, size, and AWS Region for steady-state applications
- Convertible Reserved Instances: Ideal when you need flexibility across Availability Zones or instance types
{{< /details >}}

{{< details summary="EC2 Instance Savings Plans">}}
Reduce costs by committing to an hourly spend for 1-3 years, offering savings up to 72% compared to On-Demand rates.
{{< /details >}}

{{< details summary="Spot Instances">}}
Ideal for flexible, interruptible workloads, offering up to 90% savings by using unused EC2 capacity.
{{< /details >}}

{{< details summary="Dedicated Hosts">}}
Physical servers fully dedicated to your use (most expensive option).
{{< /details >}}

### Amazon EC2 Auto Scaling

Amazon EC2 Auto Scaling enables you to automatically add or remove Amazon EC2 instances in response to changing application demands.
- **Dynamic scaling** responds to changing demand.
- **Predictive scaling** automatically schedules the right number of Amazon EC2 instances based on predicted demand.

### What types of scaling there are?:

{{< details summary="Minimum Capacity">}}
The number of Amazon EC2 instances that launch immediately after creating the Auto Scaling group.
{{< /details >}}

{{< details summary="Desired Capacity">}}
The current number of instances running in your Auto Scaling group, which may be set higher than your minimum requirement (e.g., 2 instances when only 1 is needed).
{{< /details >}}

{{< details summary="Maximum Capacity">}}
The upper limit that your Auto Scaling group can scale to in response to increased demand.
{{< /details >}}

## 3. Elastic Load Balancing

- Elastic Load Balancing is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances.
- A load balancer is an application that takes in requests and routes them to the instances to be processed.

{{< image src="https://i.imgur.com/iKkJymD.png" alt="ELB" position="center" height="300px">}}

## 4. Messaging and Queuing

### 4.1 Amazon Simple Queue Service or SQS

SQS allows you to send, store, and receive messages between software components at any volume. This is without losing messages or requiring other services to be available.

### 4.2 Amazon Simple Notification Service or SNS

Amazon SNS is similar in that it is used to send out messages to services, but it can also send out notifications to end users. It does this in a different way called a publish/subscribe or pub/sub model. This means that you can create something called an SNS topic which is just a channel for messages to be delivered.

## 5. Serverless computing

### AWS Lambda

AWS Lambda is a service that lets you run code without needing to provision or manage servers.

{{< image src="https://i.imgur.com/NS3Xi9Z.png" alt="Lambda" position="center">}}

While using AWS Lambda, you pay only for the compute time that you consume. Charges apply only when your code is running. You can also run code for virtually any type of application or backend service, all with zero administration.

### What is the difference between Serverless and Serverful computing?

{{< details summary="Serverless">}}
1. You upload your code to Lambda.
2. You set your code to trigger from an event source, such as AWS services, mobile applications, or HTTP endpoints.
3. Lambda runs your code only when triggered.
{{< /details >}}

{{< details summary="Serverful">}}
1. Provision instances (virtual servers)
2. Upload your code.
3. Continue to manage the instances while your application is running.
4. Manage the instances while your application is running.
{{< /details >}}

## 6. Other Services

### Amazon Elastic Container Service (Amazon ECS)

A highly scalable, high-performance container management system that enables you to run and scale containerized applications on AWS.

### Amazon Elastic Kubernetes Service (Amazon EKS)

A fully managed service that you can use to run Kubernetes on AWS.

### AWS Fargate

AWS Fargate is a serverless compute engine for containers. It works with both Amazon ECS and Amazon EKS.

### AWS Global Infrastructure

{{< details summary="How to select the right AWS region?">}}
1. Compliance: If your company requires data to stay within a specific country, choose a Region that meets those requirements (e.g., London for UK data residency).
2. Proximity: Running infrastructure close to customers improves content delivery (e.g., a Washington, DC company might use the Singapore Region for customers there).
3. Availability: The closest Region may lack certain features, as AWS expands services gradually by building hardware in each Region.
4. Pricing: Costs vary by Region due to local tax structures (e.g., running workloads in São Paulo may be 50% more expensive than in Oregon).
{{< /details >}}

# STORAGE AND DATABASES

**IMPORTANT -> What is a instance store?**

- An instance store provides temporary block-level storage for an Amazon EC2 instance. An instance store is disk storage that is physically attached to the host computer for an EC2 instance, and therefore has the same lifespan as the instance.

- When the instance is terminated, you lose any data in the instance store.

**IMPORTANT -> What is a object storage?**

- In object storage, each object consists of data, metadata, and a key.

- The data might be an image, video, text document, or any other type of file. Metadata contains information about what the data is, how it is used, the object size, and so on. An object’s key is its unique identifier.

## Amazon Elastic Block Store (Amazon EBS)

Block-level storage volumes behave like physical hard drives.

EBS is a service that provides block-level storage volumes that you can use with Amazon EC2 instances. If you stop or terminate an Amazon EC2 instance, all the data on the attached EBS volume remains available.

When you create an EBS volume, you define the configuration (such as volume size and type) and provision it. After you create an EBS volume, it can attach to an Amazon EC2 instance.

Because EBS volumes are for data that needs to persist, it’s important to back up the data. You can take incremental backups of EBS volumes by creating Amazon EBS snapshots.

## EBS snapshot

An EBS snapshot is an incremental backup. The first snapshot of an EBS volume copies all the data, while subsequent snapshots only save the blocks of data that have changed since the last snapshot. This approach differs from full backups, where all data is copied every time, including unchanged data. Incremental backups are more efficient, saving storage space and reducing backup time compared to full backups.

## S3 Bucket

Amazon S3 (Simple Storage Service) is an object-level storage service that stores data as objects within buckets. It supports uploading any file type (e.g., images, videos, documents) and is commonly used for backups, media storage, and archiving. Amazon S3 provides unlimited storage space, with a maximum object size of 5 TB. Users can set permissions to control access and visibility of files and enable versioning to track changes to objects over time.

There are two questions you have to answer about what kind of data you want to store in S3:

1. How often you plan to retrieve data from S3?
2. How available you need your data to be in S3?

### S3 Standard

- Designed for frequently accessed data
- Stores data in a minimum of three Availability Zones
- Has a higher cost than other storage

This makes it a good choice for a wide range of use cases, such as websites, content distribution, and data analytics.

### S3 Standard-IA

- Ideal for infrequently accessed data
- Stores data in a minimum of three Availability Zones
- Has a lower storage price and higher retrieval price

### S3 One Zone-IA

- Stores data in a single Availability Zone
- Has a lower storage price than Amazon S3 Standard-IA
- if you want to save costs on storage.
- You can easily reproduce your data in the event of an Availability Zone failure.

### S3 Intelligent-Tiering

- Ideal for data with unknown or changing access patterns
- Requires a small monthly monitoring and automation fee per object

If you haven’t accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the infrequent access tier, S3 Standard-IA. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, S3 Standard.

### S3 Glacier Instant Retrieval

- Works well for archived data that requires immediate access
- Can retrieve objects within a few milliseconds

You can retrieve objects stored in the S3 Glacier Instant Retrieval storage class within milliseconds, with the same performance as S3 Standard.

### S3 Glacier Flexible Retrieval

- Low-cost storage designed for data archiving
- Able to retrieve objects within a few minutes to hours

You can retrieve objects stored in the S3 Glacier Flexible Retrieval storage class within a few hours, with a lower retrieval price than S3 Glacier Instant Retrieval.

### S3 Glacier Deep Archive

- Ideal for data that requires infrequent access and long-term retention
- Can retrieve objects within a few days

Is a low-cost storage ideal for data archiving. For example, you might use this storage class to store archived customer records or older photos and video files. You can retrieve your data from S3 Glacier Flexible Retrieval from 1 minute to 12 hours.

### S3 Glacier Deep Archive

- Lowest-cost object storage class ideal for archiving
- Able to retrieve objects within 12 hours
- All objects from this storage class are replicated and stored across at least three geographically dispersed Availability Zones.

This storage class is the lowest-cost storage in the AWS Cloud, with data retrieval from 12 to 48 hours.

### S3 Outposts

Amazon S3 Outposts delivers object storage to your on-premises AWS Outposts environment. Amazon S3 Outposts is designed to store data durably and redundantly across multiple devices and servers on your Outposts.


| **S3** | **EBS** |
| --- | --- |
| Up to 16 TiB | Unlimited storage |
| Survive termination of a EC2 instance | Individual objects up to 5 TBs |
| SDD by default | Write one/read many|
| HDD options | 99.999999999% durability |

### Amazon Elastic File System (Amazon EFS)

In file storage, multiple clients (such as users, applications, servers, and so on) can access data that is stored in shared file folders.

As you add and remove files, Amazon EFS grows and shrinks automatically. It can scale on demand to petabytes without disrupting applications.

**IMPORTANT -> EFS vs EBS?**

An Amazon EBS volume stores data in a single Availability Zone.

Amazon EFS is a regional service. It stores data in and across multiple Availability Zones.

### Amazon Relational Database Service (Amazon RDS)

Relational databases use structured query language (SQL) to store and query data. This approach allows data to be stored in an easily understandable, consistent, and scalable way.

Amazon RDS is a managed service that automates tasks such as hardware provisioning, database setup, patching, and backups.

You can integrate Amazon RDS with other services to fulfill your business and operational needs, such as using AWS Lambda to query your database from a serverless application.

- Amazon Aurora
- PostgreSQL
- MySQL
- MariaDB
- Oracle Database
- Microsoft SQL Server

### Amazon Nonrelational databases

Nonrelational databases are sometimes referred to as “NoSQL databases” because they use structures other than rows and columns to organize data. One type of structural approach for nonrelational databases is key-value pairs. With key-value pairs, data is organized into items (keys), and items have attributes (values). You can think of attributes as being different features of your data.

- DynamoDB is serverless, which means that you do not have to provision, patch, or manage servers.

- As the size of your database shrinks or grows, DynamoDB automatically scales to adjust for changes in capacity while maintaining consistent performance.


### Amazon Redshift

Amazon Redshift is a data warehousing service that you can use for big data analytics. It offers the ability to collect data from many sources and helps you to understand relationships and trends across your data.

## AWS Database Migration Service (AWS DMS)

With AWS DMS, you move data between a source database and a target database. The source and target databases(opens in a new tab) can be of the same type or different types.

**IMPORTANT -> What are the common use cases for AWS DMS?**

1. Development and test database migrations: Enabling developers to test applications against production data without affecting production users.
2. Database consolidation: Combining several databases into a single database.
3. Continuous replication: Sending ongoing copies of your data to other target sources instead of doing a one-time migration

## Amazon DocumentDB

Is a document database service that supports MongoDB workloads. (MongoDB is a document database program.)

## Amazon Neptune

Is a graph database service. You can use Amazon Neptune to build and run applications that work with highly connected datasets, such as recommendation engines, fraud detection, and knowledge graphs.

## Amazon Quantum Ledger Database (Amazon QLDB)

Is a ledger database service.

You can use Amazon QLDB to review a complete history of all the changes that have been made to your application data.

## Amazon Managed Blockchain

Is a service that you can use to create and manage blockchain networks with open-source frameworks.

Blockchain is a distributed ledger system that lets multiple parties run transactions and share data without a central authority.

## Amazon ElastiCache

Is a service that adds caching layers on top of your databases to help improve the read times of common requests.

It supports two types of data stores: Redis and Memcached.

## Amazon DynamoDB Accelerator (DAX)

Is an in-memory cache for DynamoDB.

It helps improve response times from single-digit milliseconds to microseconds.

# Module 6: Security

The shared responsibility model divides into customer responsibilities (commonly referred to as “security in the cloud”) and AWS responsibilities (commonly referred to as “security of the cloud”).

![Imgur](https://i.imgur.com/Ug19iG0.png)

## IAM

### IAM users

It represents the identity of the person or application that interacts with AWS services and resources. It consists of a name and credentials.

### IAM policies

An IAM policy is a document that allows or denies permissions to AWS services and resources.

### IAM groups

An IAM group is a collection of IAM users. When you assign an IAM policy to a group, all users in the group are granted permissions specified by the policy.

### IAM roles

An IAM role is an identity that you can assume to gain temporary access to permissions.

Before an IAM user, application, or service can assume an IAM role, they must be granted permissions to switch to the role. When someone assumes an IAM role, they abandon all previous permissions that they had under a previous role and assume the permissions of the new role.

## Compliance

AWS Artifact(opens in a new tab) is a service that provides on-demand access to AWS security and compliance reports and select online agreements. AWS Artifact consists of two main sections:

1. AWS Artifact Agreements: In AWS Artifact Agreements, you can review, accept, and manage agreements for an individual account and for all your accounts in AWS Organizations. Different types of agreements are offered to address the needs of customers who are subject to specific regulations, such as the Health Insurance Portability and Accountability Act (HIPAA).
2. AWS Artifact Reports: AWS Artifact Reports provide compliance reports from third-party auditors. These auditors have tested and verified that AWS is compliant with a variety of global, regional, and industry-specific security standards and regulations.

**IMPORTANT -> The customer compliance center?**

In the Customer Compliance Center, you can read customer compliance stories to discover how companies in regulated industries have solved various compliance, governance, and audit challenges.

- AWS answers to key compliance questions
- An overview of AWS risk and compliance
- An auditing security checklist

## Denial-of-Service Attacks

A denial-of-service (DoS) attack is a deliberate attempt to make a website or application unavailable to users. Some of them are

- A DDoS attack aims to overwhelm an application's capacity, making it unavailable. Since a single machine isn't powerful enough, attackers distribute the attack across multiple compromised machines (bots), unknowingly used to flood the target's infrastructure.

- A UDP flood attack exploits internet services like the National Weather Service, which provide large responses to small requests. The attacker sends a simple request (e.g., "Give me weather") but spoofs the return address to the victim’s server. As a result, the service floods the victim with massive amounts of data, overwhelming its capacity. This is just one of many brute-force attacks designed to exhaust a network’s resources

- HTTP-level attacks mimic legitimate user behavior, such as repeatedly performing complex product searches. These attacks come from a network of compromised bots, overwhelming the server with excessive requests. As a result, real customers are unable to access the service.

- The Slowloris attack exploits server connection limits by making slow, incomplete requests, forcing the server to keep connections open indefinitely. This is like someone taking excessively long to order at a coffee shop, blocking others from being served. A few attackers can exhaust server resources, severely impacting availability.

### AWS Shield

AWS Shield is a service that protects applications against DDoS attacks. AWS Shield provides two levels of protection: Standard and Advanced.

## Dictionary

- **IOPS**: The term input/output operations per second (IOPS) is a metric that measures the performance of a storage device.
